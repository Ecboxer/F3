{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bert-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install torch==1.12.1 torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/osultan/Documents/01-PhD/01-Studying/08-Fall_24/F3 Project/Trial 3/F3 Codebase/Datasets/Co-AidPost_GTP3.5_Real_Posts_Output_Data\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "# os.chdir('AlignScore')\n",
    "\n",
    "# Verify current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')\n",
    "os.chdir('X-GenPost_GTP3.5_Real_Posts_Output_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install spacy\n",
    "# !pip install spacy\n",
    "\n",
    "# Download the required spaCy model\n",
    "# !python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alignscore import AlignScore\n",
    "import pandas as pd\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spacy_version': '3.7.5', 'location': '/Users/osultan/anaconda3/lib/python3.10/site-packages/spacy', 'platform': 'macOS-12.6-x86_64-i386-64bit', 'python_version': '3.10.10', 'pipelines': {}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#print(spacy.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install spacy\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/Users/osultan/anaconda3/bin/pip install spacy\n",
    "#!/Users/osultan/anaconda3/bin/python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "print(\"spaCy model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en_core_web_sm': '3.7.1'}\n"
     ]
    }
   ],
   "source": [
    "print(spacy.info()['pipelines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>human_written_content</th>\n",
       "      <th>aigenerated_content</th>\n",
       "      <th>model</th>\n",
       "      <th>num_completion_token</th>\n",
       "      <th>num_original_token</th>\n",
       "      <th>num_prompt_token</th>\n",
       "      <th>num_iagenerated_token</th>\n",
       "      <th>original_label</th>\n",
       "      <th>source_type</th>\n",
       "      <th>ai_generated_label</th>\n",
       "      <th>article_type</th>\n",
       "      <th>pre_post_GPT</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a6477508-e98c-4d3b-bb5f-04521a092609</td>\n",
       "      <td>as of todays reports the global number of conf...</td>\n",
       "      <td>The World Health Organization (WHO) has highli...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>175</td>\n",
       "      <td>231</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>real</td>\n",
       "      <td>news article</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>CoAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60343d09-529c-45f9-a157-d95cfb70ee83</td>\n",
       "      <td>\"And they have almost the same numbers. What i...</td>\n",
       "      <td>Michigan has a significantly higher percentage...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>158</td>\n",
       "      <td>201</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>real</td>\n",
       "      <td>twitter post</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>CoAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>061da836-d0cf-4418-afa0-cbbd2cae37e0</td>\n",
       "      <td>a new poll found that 58 percent of respondent...</td>\n",
       "      <td>A recent survey revealed that 58% of participa...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>75</td>\n",
       "      <td>92</td>\n",
       "      <td>187</td>\n",
       "      <td>262</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>real</td>\n",
       "      <td>news article</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>CoAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1243e23f-c38e-43ca-8fa3-99c07eaa549e</td>\n",
       "      <td>\"Whatever happened to Cummings &amp; Co's herd imm...</td>\n",
       "      <td>Exploring the status of Cummings &amp; Co's herd i...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>34</td>\n",
       "      <td>26</td>\n",
       "      <td>127</td>\n",
       "      <td>161</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>real</td>\n",
       "      <td>twitter post</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>CoAID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3e696b1f-49ac-4571-87e0-d528b5ef9428</td>\n",
       "      <td>scientists have found that four young males wh...</td>\n",
       "      <td>A recent study revealed that four young Dutch ...</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>56</td>\n",
       "      <td>80</td>\n",
       "      <td>174</td>\n",
       "      <td>230</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>real</td>\n",
       "      <td>news article</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>CoAID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  \\\n",
       "0  a6477508-e98c-4d3b-bb5f-04521a092609   \n",
       "1  60343d09-529c-45f9-a157-d95cfb70ee83   \n",
       "2  061da836-d0cf-4418-afa0-cbbd2cae37e0   \n",
       "3  1243e23f-c38e-43ca-8fa3-99c07eaa549e   \n",
       "4  3e696b1f-49ac-4571-87e0-d528b5ef9428   \n",
       "\n",
       "                               human_written_content  \\\n",
       "0  as of todays reports the global number of conf...   \n",
       "1  \"And they have almost the same numbers. What i...   \n",
       "2  a new poll found that 58 percent of respondent...   \n",
       "3  \"Whatever happened to Cummings & Co's herd imm...   \n",
       "4  scientists have found that four young males wh...   \n",
       "\n",
       "                                 aigenerated_content               model  \\\n",
       "0  The World Health Organization (WHO) has highli...  gpt-3.5-turbo-0125   \n",
       "1  Michigan has a significantly higher percentage...  gpt-3.5-turbo-0125   \n",
       "2  A recent survey revealed that 58% of participa...  gpt-3.5-turbo-0125   \n",
       "3  Exploring the status of Cummings & Co's herd i...  gpt-3.5-turbo-0125   \n",
       "4  A recent study revealed that four young Dutch ...  gpt-3.5-turbo-0125   \n",
       "\n",
       "   num_completion_token  num_original_token  num_prompt_token  \\\n",
       "0                    56                  80               175   \n",
       "1                    43                  64               158   \n",
       "2                    75                  92               187   \n",
       "3                    34                  26               127   \n",
       "4                    56                  80               174   \n",
       "\n",
       "   num_iagenerated_token original_label source_type ai_generated_label  \\\n",
       "0                    231           real  AI Machine               real   \n",
       "1                    201           real  AI Machine               real   \n",
       "2                    262           real  AI Machine               real   \n",
       "3                    161           real  AI Machine               real   \n",
       "4                    230           real  AI Machine               real   \n",
       "\n",
       "   article_type pre_post_GPT dataset_source  \n",
       "0  news article      pre-GPT          CoAID  \n",
       "1  twitter post      pre-GPT          CoAID  \n",
       "2  news article      pre-GPT          CoAID  \n",
       "3  twitter post      pre-GPT          CoAID  \n",
       "4  news article      pre-GPT          CoAID  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"Critical_articles_1-100.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.7.7 to v1.9.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../AlignScore-base.ckpt`\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/osultan/anaconda3/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:255: UserWarning: Found keys that are not in the model state dict but in the checkpoint: ['base_model.embeddings.position_ids']\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize AlignScore\n",
    "scorer = AlignScore(\n",
    "    model='roberta-base',                # Model backbone\n",
    "    batch_size=32,                       # Batch size\n",
    "    device='cpu',                        # Change to 'cpu' if no GPU is available\n",
    "    ckpt_path='/Users/osultan/Documents/01-PhD/01-Studying/08-Fall_24/F3 Project/Trial 3/F3 Codebase/AlignScore-base.ckpt',    # Path to the checkpoint file\n",
    "    evaluation_mode='nli_sp'             # Default evaluation mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint file found at: AlignScore-base.ckpt\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # Path to the checkpoint\n",
    "# ckpt_path = 'AlignScore-base.ckpt'\n",
    "\n",
    "# # Check if the file exists\n",
    "# if os.path.exists(ckpt_path):\n",
    "#     print(f\"Checkpoint file found at: {ckpt_path}\")\n",
    "# else:\n",
    "#     print(f\"Checkpoint file not found at: {ckpt_path}. Please verify the path.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:03<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "#score = scorer.score(contexts=['hello world.'], claims=['hello world.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9947293400764465]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate AlignScore\n",
    "def calculate_alignscore(human_texts, ai_texts):\n",
    "    \"\"\"\n",
    "    Calculate AlignScore for a list of human-written and AI-generated texts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores = scorer.score(contexts=human_texts, claims=ai_texts)\n",
    "    except Exception as e:\n",
    "        scores = [f\"Error: {str(e)}\"] * len(human_texts)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [18:41<00:00, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignScore calculation completed. Results saved to alignscore_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare texts for batch processing\n",
    "batch_size = 100\n",
    "align_scores = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    human_texts = batch[\"human_written_content\"].tolist()\n",
    "    ai_texts = batch[\"aigenerated_content\"].tolist()\n",
    "    batch_scores = calculate_alignscore(human_texts, ai_texts)\n",
    "    align_scores.extend(batch_scores)\n",
    "\n",
    "# Add AlignScore to the DataFrame\n",
    "df[\"AlignScore\"] = align_scores\n",
    "\n",
    "# Save results to a new CSV file\n",
    "df.to_csv(\"alignscore_results.csv\", index=False)\n",
    "\n",
    "print(\"AlignScore calculation completed. Results saved to alignscore_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bert_score import score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate BERTScore\n",
    "def calculate_bertscore(human_text, ai_text, model_type=\"roberta-large\"):\n",
    "    \"\"\"\n",
    "    Calculate BERTScore for contextual alignment.\n",
    "\n",
    "    Args:\n",
    "        human_text (str): The human-written content.\n",
    "        ai_text (str): The AI-generated content.\n",
    "        model_type (str): The pretrained model to use for BERTScore (default is 'roberta-large').\n",
    "\n",
    "    Returns:\n",
    "        dict: Precision, Recall, and F1 BERTScore.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate BERTScore\n",
    "        P, R, F1 = score([ai_text], [human_text], model_type=model_type, lang=\"en\", verbose=True)\n",
    "        return {\n",
    "            \"BERTScore_Precision\": P.item(),\n",
    "            \"BERTScore_Recall\": R.item(),\n",
    "            \"BERTScore_F1\": F1.item()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"Error\": str(e)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over DataFrame and calculate BERTScore for each row\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    human_text = row[\"human_written_content\"]\n",
    "    ai_text = row[\"aigenerated_content\"]\n",
    "    bertscore_result = calculate_bertscore(human_text, ai_text)\n",
    "    results.append({\n",
    "        \"human_written_content\": human_text,\n",
    "        \"ai_generated_content\": ai_text,\n",
    "        **bertscore_result\n",
    "    })\n",
    "\n",
    "# Save results to a new DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"bertscore_results.csv\", index=False)\n",
    "\n",
    "print(\"BERTScore results have been saved to 'bertscore_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # You can choose other models based on accuracy vs. speed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate semantic distance\n",
    "def calculate_semantic_distance(human_text, ai_text):\n",
    "    \"\"\"\n",
    "    Calculate semantic distance between human-written and AI-generated content.\n",
    "\n",
    "    Args:\n",
    "        human_text (str): The human-written content.\n",
    "        ai_text (str): The AI-generated content.\n",
    "\n",
    "    Returns:\n",
    "        float: The semantic distance between the two texts.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get embeddings for both texts\n",
    "        human_embedding = model.encode(human_text, convert_to_tensor=True)\n",
    "        ai_embedding = model.encode(ai_text, convert_to_tensor=True)\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        similarity = util.cos_sim(human_embedding, ai_embedding).item()\n",
    "\n",
    "        # Calculate semantic distance (1 - similarity)\n",
    "        distance = 1 - similarity\n",
    "        return distance\n",
    "    except Exception as e:\n",
    "        return {\"Error\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Distance results have been saved to 'semantic_distance_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Iterate over DataFrame and calculate semantic distance for each row\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    human_text = row[\"human_written_content\"]\n",
    "    ai_text = row[\"aigenerated_content\"]\n",
    "    semantic_distance = calculate_semantic_distance(human_text, ai_text)\n",
    "    results.append({\n",
    "        \"human_written_content\": human_text,\n",
    "        \"ai_generated_content\": ai_text,\n",
    "        \"Semantic_Distance\": semantic_distance\n",
    "    })\n",
    "\n",
    "# Save results to a new DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"semantic_distance_results.csv\", index=False)\n",
    "\n",
    "print(\"Semantic Distance results have been saved to 'semantic_distance_results.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
