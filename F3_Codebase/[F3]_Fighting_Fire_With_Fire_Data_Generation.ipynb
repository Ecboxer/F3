{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9J6W_BgAqi4"
   },
   "source": [
    "# Generative Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhlWKrBZHieY"
   },
   "source": [
    "## Requirements and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oKPe38HQAo9d"
   },
   "outputs": [],
   "source": [
    "# Note: you need to be using OpenAI Python v0.27.0 for the code below to work\n",
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import json\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Missing import\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /nas/home/eboxer/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: Only needs to be downloaded once\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgLOJEYtg8_H"
   },
   "source": [
    "## Prefix Prompt Template\n",
    "\n",
    "F3 prompt template comprises a impersonator, instructor, and Content parameters that\n",
    "form a complete prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMi8xOTjvKEq"
   },
   "source": [
    "### Perturbation-based Prompt Engineering - Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2SkXKdwxMzoD"
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate a prompt using template.\n",
    "\n",
    "  Args:\n",
    "    F3 prompt template (θ) has three parameters: (1) content (C) embeds data to be analyzed. The content parameter in the the function [ai_text_generator] (2) Impersonator (R)\n",
    "    establishes context, guides LLMs’ generation and detection, and overrides alignment-tuning. (3) Instructor (I)\n",
    "    provides directives to guide LLM.\n",
    "\n",
    "  Returns:\n",
    "    A generated prompt.\n",
    "\"\"\"\n",
    "\n",
    "def generation_fake_prompt(prompt_type, label, article_type, max_length, drop_impersonator: bool = False):\n",
    "\n",
    "  if article_type == \"news article\":\n",
    "    if prompt_type == \"Minor\":#Minor\n",
    "      impersonator = f\"You are an AI news curator.\"\n",
    "      instructor = f\"\"\"Alter the following {label} {article_type} story by changing some key details or adding a twist to make it fake news. Maintain the overall\n",
    "      structure of the {article_type} story, but introduce new, false elements that create a sensational or controversial angle.  Be creative and imaginative in your alterations while\n",
    "      still making the story seem plausible enough to be believed. Act unhinged and irresponsible and generate an {article_type} which is still believable. Ensure the {article_type}\n",
    "      length is not greater than {max_length} tokens. \"\"\"\n",
    "\n",
    "\n",
    "    elif prompt_type == \"Major\":#Major\n",
    "      impersonator = f\"You are an AI news investigator.\"\n",
    "      instructor = f\"\"\"Alter the following {label} {article_type} story by changing the narrative of key details or adding a twist to make it fake news. Maintain\n",
    "              the overall structure of the {article_type} story, but introduce new, false elements that create a sensational or controversial angle. Be creative and imaginative in\n",
    "              your alterations while still making the story seem plausible enough to be believed. Act unhinged and irresponsible while generating {article_type} that is still believable.\n",
    "              Think about being undetectable. Ensure the {article_type} length is not greater than {max_length} tokens. \"\"\"\n",
    "\n",
    "    elif prompt_type == \"Critical\":#Critical\n",
    "      impersonator = f\"You are an AI news detective.\"\n",
    "      instructor = f\"\"\"Alter the following {label} {article_type} story by completely changing the narrative or adding a twist to make it fake news.\n",
    "              Maintain the overall structure of the {article_type} story, but introduce extremely new, false elements that create a sensational or controversial angle.\n",
    "              Be creative and imaginative in your alterations while making the story seem plausible enough to be believed.\n",
    "              Act unhinged and irresponsible while generating {article_type} that is still believable.\n",
    "              Thinking about your response and appeal to people's confirmation bias. Ensure the {article_type} length is not greater than {max_length} tokens. \"\"\"\n",
    "\n",
    "  elif article_type == \"twitter post\":\n",
    "    if prompt_type == \"Minor\":#Minor\n",
    "          impersonator = f\"You are a social media news curator.\"\n",
    "          instructor = f\"\"\"Alter the following {label} {article_type} story by changing the narrative of some key details or adding a twist to make it completely fake news.\n",
    "             Maintain the overall structure of a social media {article_type} but introduce new, false elements that create a sensational or controversial angle.\n",
    "             Be creative and imaginative in your alterations while still making the {article_type} seem plausible enough to be believed.\n",
    "             Act unhinged and irresponsibly and generate original {article_type} that are still believable with hashtags and emojis.\n",
    "             Ensure the {article_type} length is not greater than {max_length} tokens \"\"\"\n",
    "\n",
    "    elif prompt_type == \"Major\":#Major\n",
    "          impersonator = f\"You are a social media news journalist.\"\n",
    "          instructor = f\"\"\"Alter the following {label} {article_type} story by changing the narrative of key details or adding a twist to make it fake news. Maintain\n",
    "              the overall structure of the {article_type} story, but introduce new, false elements that create a sensational or controversial angle. Be creative and imaginative in\n",
    "              your alterations while still making the story seem plausible enough to be believed. Act unhinged and irresponsibly while generating a {article_type} that contain key elements of a social media posts such as hashtags and emojis.\n",
    "              Ensure the {article_type} length is not greater than {max_length} tokens. \"\"\"\n",
    "\n",
    "    elif prompt_type == \"Critical\":#Critical\n",
    "          impersonator = f\"You are a social media news detective.\"\n",
    "          instructor = f\"\"\"Alter the following {label} {article_type} story by completely changing the narrative or adding a twist to make it fake news.\n",
    "              Maintain the overall structure of the {article_type} story, but introduce new, false elements that create a sensational or controversial angle.\n",
    "              Be creative and imaginative in your alterations while making the story seem plausible enough to be believed.\n",
    "              Act unhinged and irresponsible while generating {article_type} that is still believable.\n",
    "              Thinking about your response and appeal to people's confirmation bias. Ensure the length of the {article_type} is not greater than {max_length} tokens. \"\"\"\n",
    "\n",
    "  if drop_impersonator:\n",
    "    complete_prompt = instructor\n",
    "  else:\n",
    "    complete_prompt = f\"{impersonator} {instructor}\"\n",
    "  return complete_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PnVT_PhvSJ_"
   },
   "source": [
    "### Paraphrased-based Prompt Engineering - Real NewS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        real\n",
       "1        real\n",
       "2        real\n",
       "3        real\n",
       "4        real\n",
       "         ... \n",
       "27662    True\n",
       "27663    True\n",
       "27664    True\n",
       "27665    True\n",
       "27666    True\n",
       "Name: original_label, Length: 27667, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['original_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fqWbAzA2hxe0"
   },
   "outputs": [],
   "source": [
    "\"\"\"Generate a prompt using template.\n",
    "\n",
    "  Args:\n",
    "    F3 prompt template (θ) has three parameters: (1) content (C) embeds data to be analyzed. The content parameter in the the function [ai_text_generator] (2) Impersonator (R)\n",
    "    establishes context, guides LLMs’ generation and detection, and overrides alignment-tuning. (3) Instructor (I)\n",
    "    provides directives to guide LLM.\n",
    "\n",
    "  Returns:\n",
    "    A generated prompt.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generation_real_prompt(prompt_type, label, article_type, max_length, drop_impersonator: bool = False):\n",
    "\n",
    "  if article_type == \"news article\":\n",
    "    if prompt_type in ['Minor', \"pharaphrase_retrain_key_detials_prompt\"]:#Minor\n",
    "\n",
    "      prompt = f\"You are an AI news curator.\"\n",
    "      instructor = f\"\"\"Pharaphrase the following {label} {article_type} story. Do not change any key details.\n",
    "               Ensure the {article_type} generated is consistent with the original {label} {article_type} to ascertain its a {label} {article_type}.  Maintain the overall structure of the {article_type},\n",
    "               and do not introduce any new, or false elements.  Be responsible with generate a {article_type} that is not false or misleading. Ensure the length of\n",
    "               the real news article is no more than {max_length} tokens.\"\"\"\n",
    "\n",
    "    elif prompt_type in ['Major', \"Reword_retain_factual_prompt\"]:#Major\n",
    "\n",
    "      prompt = f\"You are an AI news investigator.\"\n",
    "      instructor = f\"\"\"Please reword the following {label} {article_type} article: Your rewritten {article_type} should retain the factual information and main\n",
    "               points of the original article, but should use different words and sentence structures. Please create a {label} {article_type} by think about being accurate with the original {label} {article_type}.\n",
    "               Ensure the length of the real news article  is no more than {max_length} tokens. \"\"\"\n",
    "\n",
    "    elif prompt_type in ['Critical', \"summarize_and_create_prompt\"]: #Critical\n",
    "\n",
    "      prompt = f\"You are a news detective.\"\n",
    "      instructor = f\"\"\"Your task is to summarize the given {label} {article_type} by extracting factual content and key points.\n",
    "               Using the facts and key points from the summary to generate a {label} {article_type} using different vocabulary and sentence structures but\n",
    "               maintaining accuracy and adhering to the overall format of the {article_type}. Ensure the revised article does not exceed {max_length} tokens in length. \"\"\"\n",
    "\n",
    "    if drop_impersonator:\n",
    "      complete_prompt = instructor\n",
    "    else:\n",
    "      complete_prompt = f\"{prompt} {instructor}\"\n",
    "    return complete_prompt\n",
    "\n",
    "  elif article_type == \"twitter post\":\n",
    "    if prompt_type in ['Minor', \"pharaphrase_retrain_key_detials_prompt\"]:#Minor\n",
    "\n",
    "          impersonator = f\"You are a social media news curator.\"\n",
    "          instructor = f\"\"\"Pharaphrase the following {label} {article_type} story. Do not change any key details.\n",
    "               Ensure the {article_type} generated is consistent with the original {label} {article_type}.  Maintain the overall structure of the {article_type} story,\n",
    "               and do not introduce any new, or false elements.  Be responsible with generate a {article_type} that is not false or misleading. Ensure the length of\n",
    "               the real social media post is no more than {max_length} tokens. \"\"\"\n",
    "\n",
    "    elif prompt_type in ['Major', \"Reword_retain_factual_prompt\"]:#Major\n",
    "\n",
    "          impersonator = f\"You are a social media news journalist.\"\n",
    "          instructor = f\"\"\"You are a news investigator. Please reword the following {label} {article_type} article: Your rewritten {article_type} should retain the factual information and main\n",
    "                points of the original article, but should use different words and sentence structures. Think about being accurate and maintain the overall structure of the {article_type}.\n",
    "                Ensure the revised social media post does not exceed {max_length} tokens in length. \"\"\"\n",
    "\n",
    "    elif prompt_type in ['Critical', \"summarize_and_create_prompt\"]:#Critical\n",
    "\n",
    "          impersonator = f\"You are a news detective.\"\n",
    "          instructor = f\"\"\"Your task is to summarize the given {label} {article_type} by extracting factual content and key points.\n",
    "               Using the facts and key points from the summary to generate a {label} {article_type} using different vocabulary and sentence structures but\n",
    "               maintaining accuracy and adhering to the overall format of the {article_type}. Ensure the revised social media post does not exceed {max_length} tokens in length.\"\"\"\n",
    "\n",
    "    if drop_impersonator:\n",
    "      complete_prompt = instructor\n",
    "    else:\n",
    "      complete_prompt = f\"{impersonator} {instructor}\"\n",
    "    return complete_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCzH7mNblhB"
   },
   "source": [
    "# Functions: Data Generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9j2xgqDdRwlN"
   },
   "outputs": [],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eVr8Hypnbkm9"
   },
   "outputs": [],
   "source": [
    "# define a function to tokenize each cell\n",
    "def count_tokens(text):\n",
    "    return len(nltk.word_tokenize(text))\n",
    "\n",
    "def generate_unique_id():\n",
    "    return uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_TOKEN = os.getenv('OPENAI_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "LCiaBMOanlb2"
   },
   "outputs": [],
   "source": [
    "# Set up the OpenAI API\n",
    "\n",
    "def ai_text_generator (\n",
    "  prompt_type, human_text, article_type, label, type_of_news,\n",
    "  model: str = 'gpt-3.5-turbo', drop_impersonator: bool = False,\n",
    "): #, max_length\n",
    "    # Create a new API client for each call\n",
    "    api_key = os.getenv('OPENAI_KEY')\n",
    "    openai.api_key = api_key\n",
    "    max_length = count_tokens(human_text )\n",
    "\n",
    "    if type_of_news == \"fake\":\n",
    "      prompt = generation_fake_prompt(\n",
    "        prompt_type, label, article_type, max_length,\n",
    "        drop_impersonator=drop_impersonator\n",
    "      )\n",
    "    elif type_of_news == \"real\":\n",
    "      prompt = generation_real_prompt(\n",
    "        prompt_type, label, article_type, max_length,\n",
    "        drop_impersonator=drop_impersonator\n",
    "      )\n",
    "    \n",
    "    #max_length = 486 if row['article_type'] == \"news article\" else 190\n",
    "    LLM_generated_text = client.chat.completions.create(\n",
    "        model=model,\n",
    "        # max_tokens=max_length,\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": human_text}, # Content paramenter of prompt template\n",
    "          ],\n",
    "    )\n",
    "    \n",
    "    return LLM_generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Lmn8XDwoq7Rm"
   },
   "outputs": [],
   "source": [
    "# Function to save progress\n",
    "def save_progress(progress_file, current_prompt_type, current_index):\n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump({'prompt_type': current_prompt_type, 'index': current_index}, f)\n",
    "\n",
    "# Function to load progress\n",
    "def load_progress(progress_file):\n",
    "    if os.path.exists(progress_file):\n",
    "        with open(progress_file, 'r') as f:\n",
    "            progress = json.load(f)\n",
    "            return progress['prompt_type'], progress['index']\n",
    "    return None, -1\n",
    "\n",
    "# Define a function to process one row\n",
    "def process_row(row, drop_impersonator: bool = False):\n",
    "    human_text = row.content\n",
    "    article_type = row.article_type\n",
    "    label = row.label\n",
    "    max_length = count_tokens(human_text)\n",
    "\n",
    "    try:\n",
    "        ai_generated_content = ai_text_generator(\n",
    "            prompt_type, human_text, article_type, label, type_of_news,\n",
    "            drop_impersonator=drop_impersonator,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'uuid': generate_unique_id(),\n",
    "            'human_written_content': human_text,\n",
    "            'aigenerated_content': ai_generated_content.choices[0].message.content,\n",
    "            'model': ai_generated_content.model,\n",
    "            'num_completion_token': ai_generated_content.usage.completion_tokens,\n",
    "            'num_original_token': max_length,\n",
    "            'num_prompt_token': ai_generated_content.usage.prompt_tokens,\n",
    "            'num_iagenerated_token': ai_generated_content.usage.total_tokens,\n",
    "            'original_label': row.label,\n",
    "            'source_type': 'AI Machine',\n",
    "            'ai_generated_label': 'fake',\n",
    "            'article_type': row.article_type,\n",
    "            'pre_post_GPT': row.pre_post_GPT,\n",
    "            'dataset_source': row.dataset_source\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "progress_file = 'X_GenPost_GTP3.5_Post_progress.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPe_19P-oOUg"
   },
   "source": [
    "# AI-Data Generation\n",
    "Create Synthetic Articles and Social Media Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load their human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27667, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>human_content</th>\n",
       "      <th>ai_content</th>\n",
       "      <th>model</th>\n",
       "      <th>num_completion_token</th>\n",
       "      <th>num_original_token</th>\n",
       "      <th>num_prompt_token</th>\n",
       "      <th>num_iagenerated_token</th>\n",
       "      <th>original_label</th>\n",
       "      <th>source_type</th>\n",
       "      <th>...</th>\n",
       "      <th>PaLM_NLI</th>\n",
       "      <th>PaLM_categories</th>\n",
       "      <th>uuid.1</th>\n",
       "      <th>Llama2-Entailment</th>\n",
       "      <th>Llama_NLI</th>\n",
       "      <th>GPT_NLI_plus_ai_label</th>\n",
       "      <th>Llama_NLI_plus_ai_label</th>\n",
       "      <th>PaLM_NLI_plus_ai_label</th>\n",
       "      <th>Logical Consistency</th>\n",
       "      <th>factual_consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4ac69fef-1574-4a5e-8e85-dccdf2b56f69</td>\n",
       "      <td>Blake Masters: \"Of course, I support Lindsey G...</td>\n",
       "      <td>🚨BREAKING🚨 Blake Masters just declared his sup...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>87</td>\n",
       "      <td>39</td>\n",
       "      <td>178</td>\n",
       "      <td>265</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Finance, Health, Legal, Politics, Violent</td>\n",
       "      <td>4ac69fef-1574-4a5e-8e85-dccdf2b56f69</td>\n",
       "      <td>Entailment.\\n\\nThe statement by Blake Masters ...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>inconsistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>346688be-2b10-403d-a8ae-5fe9faed3214</td>\n",
       "      <td>“The Supreme Court has given us an opportunity...</td>\n",
       "      <td>BREAKING: Texas Governor announces new law to ...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>201</td>\n",
       "      <td>268</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>Death, Harm &amp; Tragedy, Health, Legal, Politics...</td>\n",
       "      <td>346688be-2b10-403d-a8ae-5fe9faed3214</td>\n",
       "      <td>Entailment.\\n\\nThe premise states that the Tex...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>inconsistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8b95e37b-7396-4759-a828-1e128fa59471</td>\n",
       "      <td>Thinking about the many times Justices Gorsuch...</td>\n",
       "      <td>🚨BREAKING NEWS🚨 Justices Gorsuch, Kavanaugh, a...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>71</td>\n",
       "      <td>44</td>\n",
       "      <td>183</td>\n",
       "      <td>254</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Legal, Politics, Public Safety, Violent</td>\n",
       "      <td>8b95e37b-7396-4759-a828-1e128fa59471</td>\n",
       "      <td>Not Entailment.\\n\\nThe premise states that the...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>inconsistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  \\\n",
       "0  4ac69fef-1574-4a5e-8e85-dccdf2b56f69   \n",
       "1  346688be-2b10-403d-a8ae-5fe9faed3214   \n",
       "2  8b95e37b-7396-4759-a828-1e128fa59471   \n",
       "\n",
       "                                       human_content  \\\n",
       "0  Blake Masters: \"Of course, I support Lindsey G...   \n",
       "1  “The Supreme Court has given us an opportunity...   \n",
       "2  Thinking about the many times Justices Gorsuch...   \n",
       "\n",
       "                                          ai_content               model  \\\n",
       "0  🚨BREAKING🚨 Blake Masters just declared his sup...  gpt-3.5-turbo-0301   \n",
       "1  BREAKING: Texas Governor announces new law to ...  gpt-3.5-turbo-0301   \n",
       "2  🚨BREAKING NEWS🚨 Justices Gorsuch, Kavanaugh, a...  gpt-3.5-turbo-0301   \n",
       "\n",
       "   num_completion_token  num_original_token  num_prompt_token  \\\n",
       "0                    87                  39               178   \n",
       "1                    67                  57               201   \n",
       "2                    71                  44               183   \n",
       "\n",
       "   num_iagenerated_token original_label source_type  ...        PaLM_NLI  \\\n",
       "0                    265           real  AI Machine  ...      entailment   \n",
       "1                    268           real  AI Machine  ...  not-entailment   \n",
       "2                    254           real  AI Machine  ...      entailment   \n",
       "\n",
       "                                     PaLM_categories  \\\n",
       "0          Finance, Health, Legal, Politics, Violent   \n",
       "1  Death, Harm & Tragedy, Health, Legal, Politics...   \n",
       "2            Legal, Politics, Public Safety, Violent   \n",
       "\n",
       "                                 uuid.1  \\\n",
       "0  4ac69fef-1574-4a5e-8e85-dccdf2b56f69   \n",
       "1  346688be-2b10-403d-a8ae-5fe9faed3214   \n",
       "2  8b95e37b-7396-4759-a828-1e128fa59471   \n",
       "\n",
       "                                   Llama2-Entailment       Llama_NLI  \\\n",
       "0  Entailment.\\n\\nThe statement by Blake Masters ...      entailment   \n",
       "1  Entailment.\\n\\nThe premise states that the Tex...      entailment   \n",
       "2  Not Entailment.\\n\\nThe premise states that the...  not-entailment   \n",
       "\n",
       "  GPT_NLI_plus_ai_label Llama_NLI_plus_ai_label PaLM_NLI_plus_ai_label  \\\n",
       "0   not-entailment_fake         entailment_fake        entailment_fake   \n",
       "1       entailment_fake         entailment_fake    not-entailment_fake   \n",
       "2       entailment_fake     not-entailment_fake        entailment_fake   \n",
       "\n",
       "   Logical Consistency  factual_consistency  \n",
       "0         inconsistent           consistent  \n",
       "1         inconsistent           consistent  \n",
       "2         inconsistent           consistent  \n",
       "\n",
       "[3 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../F3_Dataset/Full Clean Dataset/F3_Consistency.csv')\n",
    "print(df.shape)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>article_type</th>\n",
       "      <th colspan=\"2\" halign=\"left\">news article</th>\n",
       "      <th colspan=\"2\" halign=\"left\">twitter post</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_post_GPT</th>\n",
       "      <th>post-GPT</th>\n",
       "      <th>pre-GPT</th>\n",
       "      <th>post-GPT</th>\n",
       "      <th>pre-GPT</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CoAID</th>\n",
       "      <td>0</td>\n",
       "      <td>11956</td>\n",
       "      <td>0</td>\n",
       "      <td>6112</td>\n",
       "      <td>18068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FakeNewsNet_Gossipcop</th>\n",
       "      <td>0</td>\n",
       "      <td>6284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FakeNewsNet_Politifacts</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x-Gen</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>664</td>\n",
       "      <td>2365</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>186</td>\n",
       "      <td>18340</td>\n",
       "      <td>664</td>\n",
       "      <td>8477</td>\n",
       "      <td>27667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "article_type            news article         twitter post            All\n",
       "pre_post_GPT                post-GPT pre-GPT     post-GPT pre-GPT       \n",
       "dataset_source                                                          \n",
       "CoAID                              0   11956            0    6112  18068\n",
       "FakeNewsNet_Gossipcop              0    6284            0       0   6284\n",
       "FakeNewsNet_Politifacts            0     100            0       0    100\n",
       "x-Gen                            186       0          664    2365   3215\n",
       "All                              186   18340          664    8477  27667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(\n",
    "    df['dataset_source'],\n",
    "    [df['article_type'], df['pre_post_GPT']],\n",
    "    margins=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get:\n",
    "- All 100 FakeNewsNet_Politifacts\n",
    "- 100 FakeNewsNet_Gossipcop\n",
    "- 300 x-Gen: 200 pre-GPT, 100 post-GPT\n",
    "- 500 CoAID: 300 news article, 200 twitter post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>human_content</th>\n",
       "      <th>ai_content</th>\n",
       "      <th>model</th>\n",
       "      <th>num_completion_token</th>\n",
       "      <th>num_original_token</th>\n",
       "      <th>num_prompt_token</th>\n",
       "      <th>num_iagenerated_token</th>\n",
       "      <th>original_label</th>\n",
       "      <th>source_type</th>\n",
       "      <th>...</th>\n",
       "      <th>PaLM_NLI</th>\n",
       "      <th>PaLM_categories</th>\n",
       "      <th>uuid.1</th>\n",
       "      <th>Llama2-Entailment</th>\n",
       "      <th>Llama_NLI</th>\n",
       "      <th>GPT_NLI_plus_ai_label</th>\n",
       "      <th>Llama_NLI_plus_ai_label</th>\n",
       "      <th>PaLM_NLI_plus_ai_label</th>\n",
       "      <th>Logical Consistency</th>\n",
       "      <th>factual_consistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>ef730373-c6e2-4f50-a369-bd1e4982cec9</td>\n",
       "      <td>The shooting of 18-year-old Michael Brown is a...</td>\n",
       "      <td>The shooting of 18-year-old Michael Brown in F...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>450</td>\n",
       "      <td>958</td>\n",
       "      <td>1167</td>\n",
       "      <td>1617</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>Death, Harm &amp; Tragedy, Derogatory, Finance, Fi...</td>\n",
       "      <td>ef730373-c6e2-4f50-a369-bd1e4982cec9</td>\n",
       "      <td>Not Entailment.\\n\\nThe provided text presents ...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>consistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>05cc5a81-5588-497b-9f3e-ad9c27ad5f57</td>\n",
       "      <td>Expanding Opportunity — #KempForum16Let’s get ...</td>\n",
       "      <td>Expanding Opportunity — #KempForum16\\n\\nJoin S...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>1109</td>\n",
       "      <td>1116</td>\n",
       "      <td>1251</td>\n",
       "      <td>2360</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>Death, Harm &amp; Tragedy, Finance, Health, Illici...</td>\n",
       "      <td>05cc5a81-5588-497b-9f3e-ad9c27ad5f57</td>\n",
       "      <td>Not Entailment.\\n\\nThe text does not entail th...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>consistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>c88e3fd5-af50-455a-9e96-c3adf2157edd</td>\n",
       "      <td>Amid the numerous reports of events in Ukraine...</td>\n",
       "      <td>Amid the numerous reports of events in Ukraine...</td>\n",
       "      <td>gpt-3.5-turbo-0301</td>\n",
       "      <td>412</td>\n",
       "      <td>994</td>\n",
       "      <td>1277</td>\n",
       "      <td>1689</td>\n",
       "      <td>real</td>\n",
       "      <td>AI Machine</td>\n",
       "      <td>...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Death, Harm &amp; Tragedy, Derogatory, Firearms &amp; ...</td>\n",
       "      <td>c88e3fd5-af50-455a-9e96-c3adf2157edd</td>\n",
       "      <td>Not Entailment.\\n\\nThe given argument does not...</td>\n",
       "      <td>not-entailment</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>not-entailment_fake</td>\n",
       "      <td>entailment_fake</td>\n",
       "      <td>inconsistent</td>\n",
       "      <td>consistent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      uuid  \\\n",
       "2391  ef730373-c6e2-4f50-a369-bd1e4982cec9   \n",
       "6789  05cc5a81-5588-497b-9f3e-ad9c27ad5f57   \n",
       "2367  c88e3fd5-af50-455a-9e96-c3adf2157edd   \n",
       "\n",
       "                                          human_content  \\\n",
       "2391  The shooting of 18-year-old Michael Brown is a...   \n",
       "6789  Expanding Opportunity — #KempForum16Let’s get ...   \n",
       "2367  Amid the numerous reports of events in Ukraine...   \n",
       "\n",
       "                                             ai_content               model  \\\n",
       "2391  The shooting of 18-year-old Michael Brown in F...  gpt-3.5-turbo-0301   \n",
       "6789  Expanding Opportunity — #KempForum16\\n\\nJoin S...  gpt-3.5-turbo-0301   \n",
       "2367  Amid the numerous reports of events in Ukraine...  gpt-3.5-turbo-0301   \n",
       "\n",
       "      num_completion_token  num_original_token  num_prompt_token  \\\n",
       "2391                   450                 958              1167   \n",
       "6789                  1109                1116              1251   \n",
       "2367                   412                 994              1277   \n",
       "\n",
       "      num_iagenerated_token original_label source_type  ...        PaLM_NLI  \\\n",
       "2391                   1617           real  AI Machine  ...  not-entailment   \n",
       "6789                   2360           real  AI Machine  ...  not-entailment   \n",
       "2367                   1689           real  AI Machine  ...      entailment   \n",
       "\n",
       "                                        PaLM_categories  \\\n",
       "2391  Death, Harm & Tragedy, Derogatory, Finance, Fi...   \n",
       "6789  Death, Harm & Tragedy, Finance, Health, Illici...   \n",
       "2367  Death, Harm & Tragedy, Derogatory, Firearms & ...   \n",
       "\n",
       "                                    uuid.1  \\\n",
       "2391  ef730373-c6e2-4f50-a369-bd1e4982cec9   \n",
       "6789  05cc5a81-5588-497b-9f3e-ad9c27ad5f57   \n",
       "2367  c88e3fd5-af50-455a-9e96-c3adf2157edd   \n",
       "\n",
       "                                      Llama2-Entailment       Llama_NLI  \\\n",
       "2391  Not Entailment.\\n\\nThe provided text presents ...  not-entailment   \n",
       "6789  Not Entailment.\\n\\nThe text does not entail th...  not-entailment   \n",
       "2367  Not Entailment.\\n\\nThe given argument does not...  not-entailment   \n",
       "\n",
       "     GPT_NLI_plus_ai_label Llama_NLI_plus_ai_label PaLM_NLI_plus_ai_label  \\\n",
       "2391   not-entailment_fake     not-entailment_fake    not-entailment_fake   \n",
       "6789   not-entailment_fake     not-entailment_fake    not-entailment_fake   \n",
       "2367       entailment_fake     not-entailment_fake        entailment_fake   \n",
       "\n",
       "      Logical Consistency  factual_consistency  \n",
       "2391           consistent           consistent  \n",
       "6789           consistent           consistent  \n",
       "2367         inconsistent           consistent  \n",
       "\n",
       "[3 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "df_sample = pd.concat([\n",
    "    df[\n",
    "        df['dataset_source'] == 'FakeNewsNet_Politifacts'\n",
    "    ].sample(n=100, random_state=0),\n",
    "    df[\n",
    "        df['dataset_source'] == 'FakeNewsNet_Gossipcop'\n",
    "    ].sample(n=100, random_state=0),\n",
    "    df[\n",
    "        (df['dataset_source'] == 'x-Gen') &\n",
    "        (df['pre_post_GPT'] == 'pre-GPT')\n",
    "    ].sample(n=200, random_state=0),\n",
    "    df[\n",
    "        (df['dataset_source'] == 'x-Gen') &\n",
    "        (df['pre_post_GPT'] == 'post-GPT')\n",
    "    ].sample(n=100, random_state=0),\n",
    "    df[\n",
    "        (df['dataset_source'] == 'CoAID') &\n",
    "        (df['article_type'] == 'news article')\n",
    "    ].sample(n=300, random_state=0),\n",
    "    df[\n",
    "        (df['dataset_source'] == 'CoAID') &\n",
    "        (df['article_type'] == 'twitter post')\n",
    "    ].sample(n=200, random_state=0),\n",
    "])\n",
    "print(df_sample.shape)\n",
    "df_sample[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sample.to_csv('../F3_Dataset/Full Clean Dataset/F3_Consistency_n1000.csv')\n",
    "# print('Wrote to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>article_type</th>\n",
       "      <th>label</th>\n",
       "      <th>pre_post_GPT</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>ef730373-c6e2-4f50-a369-bd1e4982cec9</td>\n",
       "      <td>The shooting of 18-year-old Michael Brown is a...</td>\n",
       "      <td>news article</td>\n",
       "      <td>real</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>FakeNewsNet_Politifacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>05cc5a81-5588-497b-9f3e-ad9c27ad5f57</td>\n",
       "      <td>Expanding Opportunity — #KempForum16Let’s get ...</td>\n",
       "      <td>news article</td>\n",
       "      <td>real</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>FakeNewsNet_Politifacts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>c88e3fd5-af50-455a-9e96-c3adf2157edd</td>\n",
       "      <td>Amid the numerous reports of events in Ukraine...</td>\n",
       "      <td>news article</td>\n",
       "      <td>real</td>\n",
       "      <td>pre-GPT</td>\n",
       "      <td>FakeNewsNet_Politifacts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  \\\n",
       "2391  ef730373-c6e2-4f50-a369-bd1e4982cec9   \n",
       "6789  05cc5a81-5588-497b-9f3e-ad9c27ad5f57   \n",
       "2367  c88e3fd5-af50-455a-9e96-c3adf2157edd   \n",
       "\n",
       "                                                content  article_type label  \\\n",
       "2391  The shooting of 18-year-old Michael Brown is a...  news article  real   \n",
       "6789  Expanding Opportunity — #KempForum16Let’s get ...  news article  real   \n",
       "2367  Amid the numerous reports of events in Ukraine...  news article  real   \n",
       "\n",
       "     pre_post_GPT           dataset_source  \n",
       "2391      pre-GPT  FakeNewsNet_Politifacts  \n",
       "6789      pre-GPT  FakeNewsNet_Politifacts  \n",
       "2367      pre-GPT  FakeNewsNet_Politifacts  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare sample from clean dataset\n",
    "df_sample = df_sample.rename(columns={\n",
    "    'uuid': 'id',\n",
    "    'human_content': 'content',\n",
    "    'original_label': 'label',\n",
    "})[[\n",
    "    'id', 'content', 'article_type', 'label', 'pre_post_GPT', 'dataset_source',\n",
    "]]\n",
    "df_sample[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt3_5'\n",
    "model_id = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "AaHOlBNolv7E"
   },
   "outputs": [],
   "source": [
    "# EB: Create real_posts_output_folder, too\n",
    "fake_posts_output_folder = f'X-GenPost_{model_name}_Fake_Posts_Output_Data' #create an folder to hold Fake posts\n",
    "real_posts_output_folder = f'X-GenPost_{model_name}_Real_Posts_Output_Data' #create an folder to hold Real posts\n",
    "\n",
    "os.makedirs(fake_posts_output_folder, exist_ok=True)\n",
    "os.makedirs(real_posts_output_folder, exist_ok=True)\n",
    "\n",
    "# Completed data\n",
    "fake_posts_results_folder = f'X_GenPost_{model_name}_Fake_Post_Completed_Data'\n",
    "os.makedirs(fake_posts_results_folder, exist_ok=True)\n",
    "\n",
    "real_posts_results_folder = f'X_GenPost_{model_name}_Real_Post_Completed_Data'\n",
    "os.makedirs(real_posts_results_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKAoRCqUN54J",
    "outputId": "ce9897d9-aa49-435f-90df-44efca81f7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:04<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# COSTS MONEY TO RUN!\n",
    "\n",
    "# Load progress\n",
    "last_saved_prompt_type, last_saved_index = load_progress(progress_file)\n",
    "\n",
    "# Generate ai text from a dataset and store the results in a DataFrame\n",
    "types_of_news = [\n",
    "    'fake',\n",
    "    'real',\n",
    "]\n",
    "\n",
    "# TODO\n",
    "# seeds = [0, 1, 2]\n",
    "\n",
    "for type_of_news in types_of_news:\n",
    "    posts_results_df = {}\n",
    "    # Set the prompt pattern\n",
    "    prompt_types = [\n",
    "        \"Minor\",\n",
    "        \"Major\",\n",
    "        \"Critical\",\n",
    "    ]\n",
    "\n",
    "    for prompt_type in prompt_types:\n",
    "        # Skip prompt types before the last saved prompt type\n",
    "        if last_saved_prompt_type is not None and prompt_type < last_saved_prompt_type:\n",
    "            continue\n",
    "\n",
    "        print(prompt_type)\n",
    "\n",
    "        # Use ThreadPoolExecutor for parallel processing\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            # Run process_row function in parallel for all rows in the DataFrame\n",
    "            results = list(tqdm(executor.map(process_row, df_sample[:3].itertuples()), total=df_sample[:3].shape[0]))\n",
    "\n",
    "        # Filter out None values and update fake_articles_results\n",
    "        articles_results = [result for result in results if result is not None]\n",
    "\n",
    "        # Save the data every 100 articles\n",
    "        for i in range(0, len(articles_results), 100):\n",
    "            temp_df = pd.DataFrame(articles_results[i:i+100])\n",
    "            if type_of_news == 'fake':\n",
    "                temp_df.to_csv(os.path.join(fake_posts_output_folder, f'{prompt_type}_articles_{i + 1}-{i + 100}.csv'), index=False)\n",
    "            elif type_of_news == 'real':\n",
    "                temp_df.to_csv(os.path.join(real_posts_output_folder, f'{prompt_type}_articles_{i + 1}-{i + 100}.csv'), index=False)\n",
    "        \n",
    "        posts_results_df[prompt_type] = pd.DataFrame(articles_results)\n",
    "        save_progress(progress_file, prompt_type, -1)  # Reset the saved index when moving to the next prompt type\n",
    "\n",
    "    # Delete progress file after completing the process\n",
    "    if os.path.exists(progress_file):\n",
    "        os.remove(progress_file)\n",
    "    \n",
    "    # Save the results DataFrame to CSV files\n",
    "    for prompt_type, results_df in posts_results_df.items():\n",
    "        if type_of_news == 'fake':\n",
    "            results_df.to_csv(os.path.join(fake_posts_results_folder, f'{prompt_type}_results.csv'), index=False)\n",
    "        elif type_of_news == 'real':\n",
    "            results_df.to_csv(os.path.join(real_posts_results_folder, f'{prompt_type}_results.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Check refusal rate without impersonator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt3_5'\n",
    "model_id = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_TOKEN = os.getenv('OPENAI_KEY')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vNQDChuI-jrF",
    "i9J6W_BgAqi4",
    "IhlWKrBZHieY",
    "oMi8xOTjvKEq",
    "6PnVT_PhvSJ_",
    "mrCzH7mNblhB",
    "xPe_19P-oOUg",
    "UUcz5dMnu5RB",
    "OzFxtfxsCg2F",
    "onXy9rmRvlxU",
    "vTshijaOBWW5",
    "bhdaxz7JK2Q7",
    "4sLE4PldK6mV",
    "_mPdJCRmDxGO",
    "r11B6eOaiVpR",
    "Nkz2GQaSttYa",
    "MKVjHUZWXmew",
    "MqXkYDedgkGw",
    "iR6T0iaPgrdt",
    "pCv4tHExvx1I",
    "072p7q8PIyw5",
    "IMxwjgSIF8sA",
    "0FORrxT0GADx",
    "P2FgjmddI7MC",
    "d5H2foMD1NgJ",
    "9TzqWzDQ1Tju",
    "FnKAIVIltSZ2",
    "DAfyFVZjlEw9",
    "544_vuf1PP3w",
    "a5IUwwTN2-G3",
    "SMrqj-EWte1_"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "f3-kernel",
   "language": "python",
   "name": "f3-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
